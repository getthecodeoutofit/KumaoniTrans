{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 177,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1694915254237288,
      "grad_norm": 0.3987046182155609,
      "learning_rate": 2.8474576271186442e-05,
      "loss": 12.9903,
      "step": 10
    },
    {
      "epoch": 0.3389830508474576,
      "grad_norm": 0.5666308403015137,
      "learning_rate": 2.6779661016949153e-05,
      "loss": 12.8902,
      "step": 20
    },
    {
      "epoch": 0.5084745762711864,
      "grad_norm": 0.6029431819915771,
      "learning_rate": 2.5084745762711865e-05,
      "loss": 12.8781,
      "step": 30
    },
    {
      "epoch": 0.6779661016949152,
      "grad_norm": 0.526199221611023,
      "learning_rate": 2.338983050847458e-05,
      "loss": 12.7458,
      "step": 40
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 0.6219164133071899,
      "learning_rate": 2.1694915254237287e-05,
      "loss": 12.7633,
      "step": 50
    },
    {
      "epoch": 1.0169491525423728,
      "grad_norm": 0.6337681412696838,
      "learning_rate": 1.9999999999999998e-05,
      "loss": 12.666,
      "step": 60
    },
    {
      "epoch": 1.1864406779661016,
      "grad_norm": 0.8339354395866394,
      "learning_rate": 1.8305084745762713e-05,
      "loss": 12.6861,
      "step": 70
    },
    {
      "epoch": 1.3559322033898304,
      "grad_norm": 0.8023120164871216,
      "learning_rate": 1.6610169491525424e-05,
      "loss": 12.5588,
      "step": 80
    },
    {
      "epoch": 1.5254237288135593,
      "grad_norm": 0.8421012759208679,
      "learning_rate": 1.4915254237288137e-05,
      "loss": 12.5043,
      "step": 90
    },
    {
      "epoch": 1.694915254237288,
      "grad_norm": 0.848113477230072,
      "learning_rate": 1.3220338983050848e-05,
      "loss": 12.3856,
      "step": 100
    },
    {
      "epoch": 1.8644067796610169,
      "grad_norm": 0.875805139541626,
      "learning_rate": 1.152542372881356e-05,
      "loss": 12.426,
      "step": 110
    },
    {
      "epoch": 2.0338983050847457,
      "grad_norm": 0.8643684387207031,
      "learning_rate": 9.83050847457627e-06,
      "loss": 12.3304,
      "step": 120
    },
    {
      "epoch": 2.2033898305084745,
      "grad_norm": 0.90730220079422,
      "learning_rate": 8.135593220338983e-06,
      "loss": 12.3234,
      "step": 130
    },
    {
      "epoch": 2.3728813559322033,
      "grad_norm": 0.908208429813385,
      "learning_rate": 6.440677966101695e-06,
      "loss": 12.2891,
      "step": 140
    },
    {
      "epoch": 2.542372881355932,
      "grad_norm": 0.922547459602356,
      "learning_rate": 4.745762711864408e-06,
      "loss": 12.2325,
      "step": 150
    },
    {
      "epoch": 2.711864406779661,
      "grad_norm": 0.9249427318572998,
      "learning_rate": 3.050847457627119e-06,
      "loss": 12.2211,
      "step": 160
    },
    {
      "epoch": 2.8813559322033897,
      "grad_norm": 0.7944234609603882,
      "learning_rate": 1.3559322033898304e-06,
      "loss": 12.2372,
      "step": 170
    }
  ],
  "logging_steps": 10,
  "max_steps": 177,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 192430183809024.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
