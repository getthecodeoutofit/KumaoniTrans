{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9863692688971497,
  "eval_steps": 500,
  "global_step": 603,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04956629491945477,
      "grad_norm": 4.483386039733887,
      "learning_rate": 5.161290322580645e-05,
      "loss": 3.3346,
      "step": 10
    },
    {
      "epoch": 0.09913258983890955,
      "grad_norm": 2.4313104152679443,
      "learning_rate": 0.00011612903225806453,
      "loss": 2.8415,
      "step": 20
    },
    {
      "epoch": 0.14869888475836432,
      "grad_norm": 1.8341213464736938,
      "learning_rate": 0.00018064516129032257,
      "loss": 2.1094,
      "step": 30
    },
    {
      "epoch": 0.1982651796778191,
      "grad_norm": 2.391178846359253,
      "learning_rate": 0.00019992610411116414,
      "loss": 1.477,
      "step": 40
    },
    {
      "epoch": 0.24783147459727387,
      "grad_norm": 6.350778102874756,
      "learning_rate": 0.00019956442794868992,
      "loss": 0.9373,
      "step": 50
    },
    {
      "epoch": 0.29739776951672864,
      "grad_norm": 5.808233261108398,
      "learning_rate": 0.00019890248816632796,
      "loss": 0.7217,
      "step": 60
    },
    {
      "epoch": 0.3469640644361834,
      "grad_norm": 1.5786346197128296,
      "learning_rate": 0.00019794228102357867,
      "loss": 0.6413,
      "step": 70
    },
    {
      "epoch": 0.3965303593556382,
      "grad_norm": 1.2116979360580444,
      "learning_rate": 0.00019668670228631415,
      "loss": 0.5268,
      "step": 80
    },
    {
      "epoch": 0.44609665427509293,
      "grad_norm": 1.0294106006622314,
      "learning_rate": 0.00019513953849380824,
      "loss": 0.506,
      "step": 90
    },
    {
      "epoch": 0.49566294919454773,
      "grad_norm": 3.373365879058838,
      "learning_rate": 0.0001933054555393972,
      "loss": 0.4395,
      "step": 100
    },
    {
      "epoch": 0.5452292441140025,
      "grad_norm": 1.0642212629318237,
      "learning_rate": 0.00019118998459920902,
      "loss": 0.5422,
      "step": 110
    },
    {
      "epoch": 0.5947955390334573,
      "grad_norm": 0.7700996994972229,
      "learning_rate": 0.00018879950545139696,
      "loss": 0.4938,
      "step": 120
    },
    {
      "epoch": 0.644361833952912,
      "grad_norm": 0.987236499786377,
      "learning_rate": 0.00018614122723618282,
      "loss": 0.4215,
      "step": 130
    },
    {
      "epoch": 0.6939281288723668,
      "grad_norm": 1.5766526460647583,
      "learning_rate": 0.00018322316671473343,
      "loss": 0.476,
      "step": 140
    },
    {
      "epoch": 0.7434944237918215,
      "grad_norm": 1.065402626991272,
      "learning_rate": 0.00018005412409243606,
      "loss": 0.4995,
      "step": 150
    },
    {
      "epoch": 0.7930607187112764,
      "grad_norm": 2.169092893600464,
      "learning_rate": 0.00017664365647948512,
      "loss": 0.4712,
      "step": 160
    },
    {
      "epoch": 0.8426270136307311,
      "grad_norm": 9.934340476989746,
      "learning_rate": 0.00017300204906881627,
      "loss": 0.4852,
      "step": 170
    },
    {
      "epoch": 0.8921933085501859,
      "grad_norm": 1.3835200071334839,
      "learning_rate": 0.00016914028411830876,
      "loss": 0.4743,
      "step": 180
    },
    {
      "epoch": 0.9417596034696406,
      "grad_norm": 1.6133512258529663,
      "learning_rate": 0.00016507000783079912,
      "loss": 0.4188,
      "step": 190
    },
    {
      "epoch": 0.9913258983890955,
      "grad_norm": 1.2173711061477661,
      "learning_rate": 0.0001608034952317881,
      "loss": 0.383,
      "step": 200
    },
    {
      "epoch": 1.0396530359355638,
      "grad_norm": 0.9071404337882996,
      "learning_rate": 0.00015635361315076155,
      "loss": 0.4474,
      "step": 210
    },
    {
      "epoch": 1.0892193308550187,
      "grad_norm": 2.310763359069824,
      "learning_rate": 0.00015173378141776568,
      "loss": 0.4185,
      "step": 220
    },
    {
      "epoch": 1.1387856257744733,
      "grad_norm": 2.59553599357605,
      "learning_rate": 0.00014695793239225864,
      "loss": 0.3701,
      "step": 230
    },
    {
      "epoch": 1.1883519206939281,
      "grad_norm": 0.8248370885848999,
      "learning_rate": 0.00014204046894629002,
      "loss": 0.3693,
      "step": 240
    },
    {
      "epoch": 1.2379182156133828,
      "grad_norm": 1.0432385206222534,
      "learning_rate": 0.00013699622102872176,
      "loss": 0.4552,
      "step": 250
    },
    {
      "epoch": 1.2874845105328376,
      "grad_norm": 1.3417335748672485,
      "learning_rate": 0.00013184040094148288,
      "loss": 0.3737,
      "step": 260
    },
    {
      "epoch": 1.3370508054522925,
      "grad_norm": 4.485179424285889,
      "learning_rate": 0.0001265885574627342,
      "loss": 0.3755,
      "step": 270
    },
    {
      "epoch": 1.3866171003717471,
      "grad_norm": 0.9854633212089539,
      "learning_rate": 0.00012125652895529766,
      "loss": 0.3878,
      "step": 280
    },
    {
      "epoch": 1.436183395291202,
      "grad_norm": 0.8417941331863403,
      "learning_rate": 0.00011586039560176434,
      "loss": 0.3018,
      "step": 290
    },
    {
      "epoch": 1.4857496902106568,
      "grad_norm": 1.0635478496551514,
      "learning_rate": 0.00011096251278965172,
      "loss": 0.3726,
      "step": 300
    },
    {
      "epoch": 1.5353159851301115,
      "grad_norm": 0.9495558142662048,
      "learning_rate": 0.00010603784974222861,
      "loss": 0.3981,
      "step": 310
    },
    {
      "epoch": 1.5848822800495663,
      "grad_norm": 0.9974000453948975,
      "learning_rate": 0.00010054922672361857,
      "loss": 0.3795,
      "step": 320
    },
    {
      "epoch": 1.6344485749690212,
      "grad_norm": 18.382911682128906,
      "learning_rate": 9.505894736240129e-05,
      "loss": 0.3243,
      "step": 330
    },
    {
      "epoch": 1.6840148698884758,
      "grad_norm": 0.8667806386947632,
      "learning_rate": 9.012996518299547e-05,
      "loss": 0.3531,
      "step": 340
    },
    {
      "epoch": 1.7335811648079305,
      "grad_norm": 46.60719299316406,
      "learning_rate": 8.468211838200522e-05,
      "loss": 0.3076,
      "step": 350
    },
    {
      "epoch": 1.7831474597273855,
      "grad_norm": 5.263303756713867,
      "learning_rate": 7.928046682040311e-05,
      "loss": 0.3138,
      "step": 360
    },
    {
      "epoch": 1.8327137546468402,
      "grad_norm": 104.1838607788086,
      "learning_rate": 7.447194482539544e-05,
      "loss": 0.3815,
      "step": 370
    },
    {
      "epoch": 1.8822800495662948,
      "grad_norm": 18.420841217041016,
      "learning_rate": 6.920278884078652e-05,
      "loss": 0.3389,
      "step": 380
    },
    {
      "epoch": 1.9318463444857497,
      "grad_norm": 0.6757987141609192,
      "learning_rate": 6.402651022508974e-05,
      "loss": 0.3141,
      "step": 390
    },
    {
      "epoch": 1.9814126394052045,
      "grad_norm": 8.382972717285156,
      "learning_rate": 5.8958719454724346e-05,
      "loss": 0.3342,
      "step": 400
    },
    {
      "epoch": 2.029739776951673,
      "grad_norm": 11.639100074768066,
      "learning_rate": 5.401469983149698e-05,
      "loss": 0.3694,
      "step": 410
    },
    {
      "epoch": 2.0793060718711276,
      "grad_norm": 1.2441941499710083,
      "learning_rate": 4.9209361391647066e-05,
      "loss": 0.2663,
      "step": 420
    },
    {
      "epoch": 2.1288723667905822,
      "grad_norm": 1.5106905698776245,
      "learning_rate": 4.455719594057593e-05,
      "loss": 0.2794,
      "step": 430
    },
    {
      "epoch": 2.1784386617100373,
      "grad_norm": 0.9792793989181519,
      "learning_rate": 4.007223334886531e-05,
      "loss": 0.3535,
      "step": 440
    },
    {
      "epoch": 2.228004956629492,
      "grad_norm": 1.0801572799682617,
      "learning_rate": 3.576799924138532e-05,
      "loss": 0.3763,
      "step": 450
    },
    {
      "epoch": 2.2775712515489466,
      "grad_norm": 13.334870338439941,
      "learning_rate": 3.165747420709314e-05,
      "loss": 0.3917,
      "step": 460
    },
    {
      "epoch": 2.3271375464684017,
      "grad_norm": 2.423260450363159,
      "learning_rate": 2.775305465253536e-05,
      "loss": 0.3568,
      "step": 470
    },
    {
      "epoch": 2.3767038413878563,
      "grad_norm": 1.6594103574752808,
      "learning_rate": 2.406651541711169e-05,
      "loss": 0.2806,
      "step": 480
    },
    {
      "epoch": 2.426270136307311,
      "grad_norm": 1.1859843730926514,
      "learning_rate": 2.060897426284302e-05,
      "loss": 0.3111,
      "step": 490
    },
    {
      "epoch": 2.4758364312267656,
      "grad_norm": 1.6288152933120728,
      "learning_rate": 1.739085834573564e-05,
      "loss": 0.2951,
      "step": 500
    },
    {
      "epoch": 2.5254027261462206,
      "grad_norm": 1.3912943601608276,
      "learning_rate": 1.442187276985526e-05,
      "loss": 0.3304,
      "step": 510
    },
    {
      "epoch": 2.5749690210656753,
      "grad_norm": 1.1689717769622803,
      "learning_rate": 1.1710971318945485e-05,
      "loss": 0.2935,
      "step": 520
    },
    {
      "epoch": 2.6245353159851303,
      "grad_norm": 0.9560801982879639,
      "learning_rate": 9.266329453856959e-06,
      "loss": 0.3089,
      "step": 530
    },
    {
      "epoch": 2.674101610904585,
      "grad_norm": 1.1206614971160889,
      "learning_rate": 7.095319657220889e-06,
      "loss": 0.3362,
      "step": 540
    },
    {
      "epoch": 2.7236679058240396,
      "grad_norm": 1.1657449007034302,
      "learning_rate": 5.20448919972204e-06,
      "loss": 0.3144,
      "step": 550
    },
    {
      "epoch": 2.7732342007434942,
      "grad_norm": 4.965275764465332,
      "learning_rate": 3.5995403950225824e-06,
      "loss": 0.391,
      "step": 560
    },
    {
      "epoch": 2.8228004956629493,
      "grad_norm": 51.98930740356445,
      "learning_rate": 2.2853134028840594e-06,
      "loss": 0.3142,
      "step": 570
    },
    {
      "epoch": 2.872366790582404,
      "grad_norm": 1.0133758783340454,
      "learning_rate": 1.2657716323486225e-06,
      "loss": 0.2615,
      "step": 580
    },
    {
      "epoch": 2.9219330855018586,
      "grad_norm": 3.3192243576049805,
      "learning_rate": 5.43989789000976e-07,
      "loss": 0.3321,
      "step": 590
    },
    {
      "epoch": 2.9714993804213137,
      "grad_norm": 2.1525580883026123,
      "learning_rate": 1.2214460235703272e-07,
      "loss": 0.3159,
      "step": 600
    }
  ],
  "logging_steps": 10,
  "max_steps": 603,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2586203292303360.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
