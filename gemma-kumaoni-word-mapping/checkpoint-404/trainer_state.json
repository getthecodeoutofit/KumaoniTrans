{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 404,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04956629491945477,
      "grad_norm": 4.483386039733887,
      "learning_rate": 5.161290322580645e-05,
      "loss": 3.3346,
      "step": 10
    },
    {
      "epoch": 0.09913258983890955,
      "grad_norm": 2.4313104152679443,
      "learning_rate": 0.00011612903225806453,
      "loss": 2.8415,
      "step": 20
    },
    {
      "epoch": 0.14869888475836432,
      "grad_norm": 1.8341213464736938,
      "learning_rate": 0.00018064516129032257,
      "loss": 2.1094,
      "step": 30
    },
    {
      "epoch": 0.1982651796778191,
      "grad_norm": 2.391178846359253,
      "learning_rate": 0.00019992610411116414,
      "loss": 1.477,
      "step": 40
    },
    {
      "epoch": 0.24783147459727387,
      "grad_norm": 6.350778102874756,
      "learning_rate": 0.00019956442794868992,
      "loss": 0.9373,
      "step": 50
    },
    {
      "epoch": 0.29739776951672864,
      "grad_norm": 5.808233261108398,
      "learning_rate": 0.00019890248816632796,
      "loss": 0.7217,
      "step": 60
    },
    {
      "epoch": 0.3469640644361834,
      "grad_norm": 1.5786346197128296,
      "learning_rate": 0.00019794228102357867,
      "loss": 0.6413,
      "step": 70
    },
    {
      "epoch": 0.3965303593556382,
      "grad_norm": 1.2116979360580444,
      "learning_rate": 0.00019668670228631415,
      "loss": 0.5268,
      "step": 80
    },
    {
      "epoch": 0.44609665427509293,
      "grad_norm": 1.0294106006622314,
      "learning_rate": 0.00019513953849380824,
      "loss": 0.506,
      "step": 90
    },
    {
      "epoch": 0.49566294919454773,
      "grad_norm": 3.373365879058838,
      "learning_rate": 0.0001933054555393972,
      "loss": 0.4395,
      "step": 100
    },
    {
      "epoch": 0.5452292441140025,
      "grad_norm": 1.0642212629318237,
      "learning_rate": 0.00019118998459920902,
      "loss": 0.5422,
      "step": 110
    },
    {
      "epoch": 0.5947955390334573,
      "grad_norm": 0.7700996994972229,
      "learning_rate": 0.00018879950545139696,
      "loss": 0.4938,
      "step": 120
    },
    {
      "epoch": 0.644361833952912,
      "grad_norm": 0.987236499786377,
      "learning_rate": 0.00018614122723618282,
      "loss": 0.4215,
      "step": 130
    },
    {
      "epoch": 0.6939281288723668,
      "grad_norm": 1.5766526460647583,
      "learning_rate": 0.00018322316671473343,
      "loss": 0.476,
      "step": 140
    },
    {
      "epoch": 0.7434944237918215,
      "grad_norm": 1.065402626991272,
      "learning_rate": 0.00018005412409243606,
      "loss": 0.4995,
      "step": 150
    },
    {
      "epoch": 0.7930607187112764,
      "grad_norm": 2.169092893600464,
      "learning_rate": 0.00017664365647948512,
      "loss": 0.4712,
      "step": 160
    },
    {
      "epoch": 0.8426270136307311,
      "grad_norm": 9.934340476989746,
      "learning_rate": 0.00017300204906881627,
      "loss": 0.4852,
      "step": 170
    },
    {
      "epoch": 0.8921933085501859,
      "grad_norm": 1.3835200071334839,
      "learning_rate": 0.00016914028411830876,
      "loss": 0.4743,
      "step": 180
    },
    {
      "epoch": 0.9417596034696406,
      "grad_norm": 1.6133512258529663,
      "learning_rate": 0.00016507000783079912,
      "loss": 0.4188,
      "step": 190
    },
    {
      "epoch": 0.9913258983890955,
      "grad_norm": 1.2173711061477661,
      "learning_rate": 0.0001608034952317881,
      "loss": 0.383,
      "step": 200
    },
    {
      "epoch": 1.0396530359355638,
      "grad_norm": 0.9071404337882996,
      "learning_rate": 0.00015635361315076155,
      "loss": 0.4474,
      "step": 210
    },
    {
      "epoch": 1.0892193308550187,
      "grad_norm": 2.310763359069824,
      "learning_rate": 0.00015173378141776568,
      "loss": 0.4185,
      "step": 220
    },
    {
      "epoch": 1.1387856257744733,
      "grad_norm": 2.59553599357605,
      "learning_rate": 0.00014695793239225864,
      "loss": 0.3701,
      "step": 230
    },
    {
      "epoch": 1.1883519206939281,
      "grad_norm": 0.8248370885848999,
      "learning_rate": 0.00014204046894629002,
      "loss": 0.3693,
      "step": 240
    },
    {
      "epoch": 1.2379182156133828,
      "grad_norm": 1.0432385206222534,
      "learning_rate": 0.00013699622102872176,
      "loss": 0.4552,
      "step": 250
    },
    {
      "epoch": 1.2874845105328376,
      "grad_norm": 1.3417335748672485,
      "learning_rate": 0.00013184040094148288,
      "loss": 0.3737,
      "step": 260
    },
    {
      "epoch": 1.3370508054522925,
      "grad_norm": 4.485179424285889,
      "learning_rate": 0.0001265885574627342,
      "loss": 0.3755,
      "step": 270
    },
    {
      "epoch": 1.3866171003717471,
      "grad_norm": 0.9854633212089539,
      "learning_rate": 0.00012125652895529766,
      "loss": 0.3878,
      "step": 280
    },
    {
      "epoch": 1.436183395291202,
      "grad_norm": 0.8417941331863403,
      "learning_rate": 0.00011586039560176434,
      "loss": 0.3018,
      "step": 290
    },
    {
      "epoch": 1.4857496902106568,
      "grad_norm": 1.0635478496551514,
      "learning_rate": 0.00011096251278965172,
      "loss": 0.3726,
      "step": 300
    },
    {
      "epoch": 1.5353159851301115,
      "grad_norm": 0.9495558142662048,
      "learning_rate": 0.00010603784974222861,
      "loss": 0.3981,
      "step": 310
    },
    {
      "epoch": 1.5848822800495663,
      "grad_norm": 0.9974000453948975,
      "learning_rate": 0.00010054922672361857,
      "loss": 0.3795,
      "step": 320
    },
    {
      "epoch": 1.6344485749690212,
      "grad_norm": 18.382911682128906,
      "learning_rate": 9.505894736240129e-05,
      "loss": 0.3243,
      "step": 330
    },
    {
      "epoch": 1.6840148698884758,
      "grad_norm": 0.8667806386947632,
      "learning_rate": 9.012996518299547e-05,
      "loss": 0.3531,
      "step": 340
    },
    {
      "epoch": 1.7335811648079305,
      "grad_norm": 46.60719299316406,
      "learning_rate": 8.468211838200522e-05,
      "loss": 0.3076,
      "step": 350
    },
    {
      "epoch": 1.7831474597273855,
      "grad_norm": 5.263303756713867,
      "learning_rate": 7.928046682040311e-05,
      "loss": 0.3138,
      "step": 360
    },
    {
      "epoch": 1.8327137546468402,
      "grad_norm": 104.1838607788086,
      "learning_rate": 7.447194482539544e-05,
      "loss": 0.3815,
      "step": 370
    },
    {
      "epoch": 1.8822800495662948,
      "grad_norm": 18.420841217041016,
      "learning_rate": 6.920278884078652e-05,
      "loss": 0.3389,
      "step": 380
    },
    {
      "epoch": 1.9318463444857497,
      "grad_norm": 0.6757987141609192,
      "learning_rate": 6.402651022508974e-05,
      "loss": 0.3141,
      "step": 390
    },
    {
      "epoch": 1.9814126394052045,
      "grad_norm": 8.382972717285156,
      "learning_rate": 5.8958719454724346e-05,
      "loss": 0.3342,
      "step": 400
    }
  ],
  "logging_steps": 10,
  "max_steps": 603,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1732005026463744.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
